{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 내용은 Intel® AI for Youth 프로그램을 참고하여\n",
    "BrainAI와 BrainAI Coach Network에서 개발한 내용입니다.<br> \n",
    "상업적 사용은 불가하며 교육기관 및 학교에서 학생들 교육활동에 자유롭게 사용가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 제목: 교통 신호 인식 AI 모델링 및 모델 평가하기\n",
    "자율주행자동차가 횡단보도에 정지 한 후 교통 신호를 판단하여 신호에 따라 주행할 수 있도록 하기 위해<br>\n",
    "실시간 영상에서 관심 영역으로 지정된 교통 신호를 판단할 수 있도록 준비된 데이터로 AI 모델을 훈련하고<br>\n",
    "훈련된 AI 모델이 교통 신호를 잘 인식하는 지 모델을 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. 필요 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로젝트 수행에 필요한 라이브러리를 모두 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(\"프로젝트 수행에 필요한 라이브러리를 모두 불러왔습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. 레이블(데이터 저장 폴더) 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forward', 'left', 'noSign', 'stop', 'test']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './여기완성'\n",
    "folders=[]\n",
    "folders = [f for f in (os.listdir(data_dir))]\n",
    "\n",
    "if '.ipynb_checkpoints' in folders:\n",
    "    folders.remove('.ipynb_checkpoints')\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. 모델에 사용되는 이미지 크기 설정 및 레이블 개수 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = 48\n",
    "input_width = 48\n",
    "input_channel = 3\n",
    "\n",
    "input_shape = (input_height, input_width, input_channel)\n",
    "num_classes = len(folders) - 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. 훈련 셋, 테스트 셋, 레이블 데이터를 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = []\n",
    "testset = []\n",
    "label = []\n",
    "test_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images: forward\n",
      "Loading images: left\n",
      "Loading images: noSign\n",
      "Loading images: stop\n",
      "Loading images: test\n",
      "# of Training Images:  871\n",
      "# of Test Images:  40\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(folders)):\n",
    "    \n",
    "    print(\"Loading images: \" + folders[i])\n",
    "    data_path = os.path.join(data_dir, str(folders[i]))\n",
    "        \n",
    "    for subdir, dirs, files in os.walk(data_path):\n",
    "        for filename in files:\n",
    "            file_path = data_path + os.sep + filename\n",
    "\n",
    "            if file_path.endswith(\".jpg\") or file_path.endswith(\".png\"):\n",
    "                image = cv2.imread(file_path)\n",
    "                resized_image = cv2.resize(image,(input_width, input_height))\n",
    "\n",
    "                if folders[i] == \"test\":\n",
    "                    여기완성.append(resized_image)\n",
    "                    test_files.append(file_path)\n",
    "\n",
    "                else: \n",
    "                    여기완성.append(resized_image)\n",
    "                    \n",
    "                    label_data = np.zeros(shape = (num_classes)) \n",
    "                    label_data[i] = 1.0\n",
    "                    여기완성.append(label_data)           \n",
    "\n",
    "trainset = np.array(trainset)\n",
    "testset = np.array(testset)\n",
    "label = np.array(label)\n",
    "print(\"# of Training Images: \", trainset.shape[0])\n",
    "print(\"# of Test Images: \", testset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. 훈련데이터 및 평가데이터 정규화(0과 1 사이의 수로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = trainset / 255.0\n",
    "testset = testset / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folders.remove('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, \n",
    "                 activation='relu', \n",
    "                 kernel_initializer='he_normal', \n",
    "                 padding=\"valid\",\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, \n",
    "                 activation='relu', \n",
    "                 kernel_initializer='he_normal', \n",
    "                 padding='valid'))\n",
    "\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(256, kernel_size=3, kernel_initializer='he_normal', \n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dense(512, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7. AI 모델 최적 학습 방법 설계 및 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 6s 118ms/step - loss: 1.6844 - accuracy: 0.6663 - val_loss: 5.6417e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.0724 - accuracy: 0.9804 - val_loss: 1.1760e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 5s 113ms/step - loss: 0.0275 - accuracy: 0.9896 - val_loss: 1.4305e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.0570 - accuracy: 0.9850 - val_loss: 3.1654e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 4.1340e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 4.6883e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 4.1723e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 5s 113ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 인공지능 모델을 이용한 최적 데이터 학습 방법 설계\n",
    "adam=Adam()\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 인공지능 모델을 이용한 데이터 학습 실행\n",
    "history = model.fit(\n",
    "    trainset, label, \n",
    "    batch_size=20, \n",
    "    epochs= 10,  \n",
    "    validation_split=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_desc = model.to_json()\n",
    "with open('./model/model.json', 'w') as file_model:\n",
    "    file_model.write(model_desc)\n",
    "model.save_weights('./model/weights.h5')\n",
    "\n",
    "with open(\"./model/labels.txt\", \"w\") as txt_file:\n",
    "    for line in folders:\n",
    "        txt_file.write(line + \"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9. 평가데이터를 이용한 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name\t  forecast category\n",
      "forward (1).jpg       forward\n",
      "forward (10).jpg       forward\n",
      "forward (2).jpg       forward\n",
      "forward (3).jpg       forward\n",
      "forward (4).jpg       forward\n",
      "forward (5).jpg       forward\n",
      "forward (6).jpg       forward\n",
      "forward (7).jpg       forward\n",
      "forward (8).jpg       forward\n",
      "forward (9).jpg       forward\n",
      "left (1).jpg          left\n",
      "left (10).jpg          left\n",
      "left (2).jpg          left\n",
      "left (3).jpg          left\n",
      "left (4).jpg          left\n",
      "left (5).jpg          left\n",
      "left (6).jpg          left\n",
      "left (7).jpg          left\n",
      "left (8).jpg          left\n",
      "left (9).jpg          left\n",
      "noSign (1).jpg        noSign\n",
      "noSign (10).jpg        noSign\n",
      "noSign (2).jpg        noSign\n",
      "noSign (3).jpg        noSign\n",
      "noSign (4).jpg        noSign\n",
      "noSign (5).jpg        noSign\n",
      "noSign (6).jpg        noSign\n",
      "noSign (7).jpg        noSign\n",
      "noSign (8).jpg        noSign\n",
      "noSign (9).jpg        noSign\n",
      "stop (1).jpg          stop\n",
      "stop (10).jpg          stop\n",
      "stop (2).jpg          stop\n",
      "stop (3).jpg          stop\n",
      "stop (4).jpg          stop\n",
      "stop (5).jpg          stop\n",
      "stop (6).jpg          stop\n",
      "stop (7).jpg          stop\n",
      "stop (8).jpg          stop\n",
      "stop (9).jpg          stop\n"
     ]
    }
   ],
   "source": [
    "# 평가데이터를 이용한 예측 정확도 확인\n",
    "if testset.shape[0] != 0:\n",
    "    prediction = model.predict(testset)\n",
    "    result_predict = np.argmax(prediction, axis=1)\n",
    "else:\n",
    "    result_sparse = list()\n",
    "print('File name\\t  forecast category')\n",
    "\n",
    "# 평가 데이터 파일명에 따른 예측 결과 값 출력\n",
    "for file, label_id in zip(test_files, result_predict):\n",
    "    filename = os.path.basename(file)\n",
    "    label_name = folders[label_id] \n",
    "    print(\"{:} {: >13}\".format(filename, label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
